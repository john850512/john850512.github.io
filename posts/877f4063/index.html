<!DOCTYPE html>
<html lang="zh-TW">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="keyword"  content="programming, study, daily, entertainment">

    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="星期五。見面">
    <meta property="og:locale" content="zh-TW" />
    
    <meta property="og:title" content="[Tensorflow]從Pytorch到TF2的學習之路 - Training mode v.s. Inference mode" />
    
    
    <meta property="og:description" content="在pytorch中會使用`train()`, `eval()`來控制一些在訓練(training mode)/測試階段(inference mode)下執行不同的操作，比方說Dropout, BatchNormalization。但TF沒有這兩個function，那應該要怎麼去操控training mode / inference mode呢?本文透過Dropout, BatchNormalization的TF官方文件搭配Source code來深入研究。" />
    <meta name="description" content="在pytorch中會使用`train()`, `eval()`來控制一些在訓練(training mode)/測試階段(inference mode)下執行不同的操作，比方說Dropout, BatchNormalization。但TF沒有這兩個function，那應該要怎麼去操控training mode / inference mode呢?本文透過Dropout, BatchNormalization的TF官方文件搭配Source code來深入研究。">
    
    
    <meta property="og:image" content="/img/avatar.jpg" />
    

    <link rel="shortcut icon" href="/img/avatar.jpg">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          [Tensorflow]從Pytorch到TF2的學習之路 - Training mode v.s. Inference mode - MeetonFriday
        
    </title>
    <!-- canonical -->
    
    
      <link rel="canonical" href="https://meetonfriday.com/posts/877f4063/">
    

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
<link rel="stylesheet" href="/css/dusign-dark.css">

    
<link rel="stylesheet" href="/css/dusign-common-dark.css">

    <!-- 
<link rel="stylesheet" href="/css/font-awesome.css">
 -->
    
<link rel="stylesheet" href="/css/toc.css">


    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <!-- <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css">
    
    <!-- Google Analytics -->
    
      <!-- <script>
          // dynamic User by Hux
          var _gaId = 'UA-163346001-1';
          var _gaDomain = 'auto';
      
          // Originial
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      
          ga('create', _gaId, _gaDomain);
          ga('send', 'pageview');
      </script> -->
      
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163346001-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
      
        gtag('config', 'UA-163346001-1');
      </script>
      
    <!-- google ad sense-->
    <script data-ad-client="ca-pub-9561340457908416" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="星期五。見面" type="application/atom+xml">
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.5)), url('/img/header_img/header-bg.jpg')
            
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#deep learning" title="deep learning">deep learning</a>
                            
                              <a class="tag" href="/tags/#pytorch" title="pytorch">pytorch</a>
                            
                              <a class="tag" href="/tags/#tensorflow" title="tensorflow">tensorflow</a>
                            
                        </div>
                        <h1>[Tensorflow]從Pytorch到TF2的學習之路 - Training mode v.s. Inference mode</h1>
                        <h2 class="subheading"></h2>
                        <span class="meta">
                            Posted by John on
                            2020-08-16
                        </span>

                        
                            <div class="blank_box"></div>
                            <span class="meta">
                                Words <span class="post-count">1.2k</span> and
                                Reading Time <span class="post-count">5</span> Minutes
                            </span>
                            <div class="blank_box"></div>
                            <!-- 不蒜子统计 start -->
                            <span class="meta">
                                Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
                            </span>
                            <!-- 不蒜子统计 end -->
                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
        
            <div class="waveWrapper">
                <div class="wave wave_before" style="background-image: url('/img/wave-dark.png')"></div>
                <div class="wave wave_after" style="background-image: url('/img/wave-dark.png')"></div>
            </div>
        
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">星期五。見面</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/categories/">Categories</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/reading/">Reading</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

    
    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->

    
        
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">
        
    

                <blockquote>
<p>「這個故事是描寫一位從原本在寫Pytorch的熱血少年，因為工作需求所以開始跳槽Tensorflow2，立志寫出厲害的TF2程式碼，在台灣締造的偉大抒情史詩」 (改寫自烘焙王開頭旁白)</p>
</blockquote>
<p>【[Tensorflow]從Pytorch到TF2的學習之路】所有文章:</p>
<ul>
<li><a href="https://meetonfriday.com/posts/1244cf1f/">[Tensorflow]從Pytorch到TF2的學習之路 - Different Padding Algorithms</a></li>
<li><a href="https://meetonfriday.com/posts/877f4063/">[Tensorflow]從Pytorch到TF2的學習之路 - Training mode v.s. Inference mode</a></li>
<li><a href="https://meetonfriday.com/posts/3e428c8a/">[Tensorflow]從Pytorch到TF2的學習之路 - Custom Model &amp; Custom training</a></li>
</ul>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在pytorch中會使用<code>train()</code>, <code>eval()</code>來控制一些在訓練(training mode)/測試階段(inference mode)下執行不同的操作，比方說Dropout, BatchNormalization</p>
<ul>
<li>Dropout在inference mode下就不會在屏蔽neuron</li>
<li>BatchNormalization在inference mode下會使用training時得到的平均值作為alpha, beta的參數</li>
</ul>
<p>但TF沒有這兩個function，那應該要怎麼去操控training mode / inference mode呢? 本文透過Dropout, BatchNormalization的TF官方文件搭配Source code來深入研究。</p>
<a id="more"></a>
<h2 id="Dropout-training參數"><a href="#Dropout-training參數" class="headerlink" title="Dropout: training參數"></a>Dropout: training參數</h2><p>在TF中則是透過參數來控制，例如Dropout可以透過training參數來控制，在<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" target="_blank" rel="noopener">官方文件</a>中寫到:</p>
<blockquote>
<p>Note that the Dropout layer only applies when training is set to True such that no values are dropped during inference. When using model.fit, training will be appropriately set to True automatically, and in other contexts, you can set the kwarg explicitly to True when calling the layer.</p>
</blockquote>
<p>也就是說透過<strong>設置training=True來開啟Dropout功能</strong>，在testing的時候設置training=False即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tf.random.set_seed(<span class="number">0</span>)</span><br><span class="line">layer = tf.keras.layers.Dropout(<span class="number">.2</span>, input_shape=(<span class="number">2</span>,))</span><br><span class="line">data = np.arange(<span class="number">10</span>).reshape(<span class="number">5</span>, <span class="number">2</span>).astype(np.float32)</span><br><span class="line">print(data)</span><br><span class="line"><span class="comment"># [[0. 1.]</span></span><br><span class="line"><span class="comment">#  [2. 3.]</span></span><br><span class="line"><span class="comment">#  [4. 5.]</span></span><br><span class="line"><span class="comment">#  [6. 7.]</span></span><br><span class="line"><span class="comment">#  [8. 9.]]</span></span><br><span class="line"></span><br><span class="line">outputs = layer(data, training=<span class="literal">True</span>)</span><br><span class="line">print(outputs)</span><br><span class="line"><span class="comment"># [[ 0.    1.25]</span></span><br><span class="line"><span class="comment">#  [ 2.5   3.75]</span></span><br><span class="line"><span class="comment">#  [ 5.    6.25]</span></span><br><span class="line"><span class="comment">#  [ 7.5   8.75]</span></span><br><span class="line"><span class="comment">#  [10.    0.  ]], shape=(5, 2), dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>此外，文件中也提到<strong>training這個參數跟trainable這個參數是不同的，trainable是只說在propagation過程中要不要更新參數，但Dropout並沒有參數，所以Dropout設置trainable是沒有用的</strong>。</p>
<blockquote>
<p>(This is in contrast to setting trainable=False for a Dropout layer. trainable does not affect the layer’s behavior, as Dropout does not have any variables/weights that can be frozen during training.)</p>
</blockquote>
<p>最後，training參數的預設值又是什麼呢? </p>
<p>首先先看Dropout的文件中提到:</p>
<blockquote>
<p>When using model.fit, training will be appropriately set to True automatically, and in other contexts, you can set the kwarg explicitly to True when calling the layer.</p>
</blockquote>
<p><strong>除了呼叫model.fit()的情況下，不然需要手動設置training=True</strong></p>
<p>所以這樣是說training預設是False嗎? 在<a href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/engine/base_layer.py#L945" target="_blank" rel="noopener">tensorflow/tensorflow/python/keras/engine/base_layer.py</a>中有提到對於training的設置考慮順序<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">945</span><br><span class="line">946</span><br><span class="line">947</span><br><span class="line">948</span><br><span class="line">949</span><br><span class="line">950</span><br><span class="line">951</span><br><span class="line">952</span><br><span class="line">953</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training mode for `Layer.call` is set via (in order of priority):</span></span><br><span class="line"><span class="comment"># (1) The `training` argument passed to this `Layer.call`, if it is not None</span></span><br><span class="line"><span class="comment"># (2) The training mode of an outer `Layer.call`.</span></span><br><span class="line"><span class="comment"># (3) The default mode set by `tf.keras.backend.set_learning_phase` (if set)</span></span><br><span class="line"><span class="comment"># (4) Any non-None default value for `training` specified in the call</span></span><br><span class="line"><span class="comment">#  signature</span></span><br><span class="line"><span class="comment"># (5) False (treating the layer as if it's in inference)</span></span><br><span class="line">args, kwargs, training_mode = self._set_training_mode(</span><br><span class="line">    args, kwargs, call_context)</span><br></pre></td></tr></table></figure></p>
<h2 id="BatchNormalization-trainable參數"><a href="#BatchNormalization-trainable參數" class="headerlink" title="BatchNormalization: trainable參數"></a>BatchNormalization: trainable參數</h2><p>而對於BatchNormalization，則是透過trainable來控制(因為BN有需要訓練的參數)，而在BN中預設trainable=True<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">0</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.BatchNormalization(</span><br><span class="line">    axis=<span class="number">-1</span>, momentum=<span class="number">0.99</span>, epsilon=<span class="number">0.001</span>, center=<span class="literal">True</span>, scale=<span class="literal">True</span>,</span><br><span class="line">    beta_initializer=<span class="string">'zeros'</span>, gamma_initializer=<span class="string">'ones'</span>,</span><br><span class="line">    moving_mean_initializer=<span class="string">'zeros'</span>, moving_variance_initializer=<span class="string">'ones'</span>,</span><br><span class="line">    beta_regularizer=<span class="literal">None</span>, gamma_regularizer=<span class="literal">None</span>, beta_constraint=<span class="literal">None</span>,</span><br><span class="line">    gamma_constraint=<span class="literal">None</span>, renorm=<span class="literal">False</span>, renorm_clipping=<span class="literal">None</span>, renorm_momentum=<span class="number">0.99</span>,</span><br><span class="line">    fused=<span class="literal">None</span>, trainable=<span class="literal">True</span>, virtual_batch_size=<span class="literal">None</span>, adjustment=<span class="literal">None</span>, name=<span class="literal">None</span>,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>在<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" target="_blank" rel="noopener">官方文件</a>中也提到:</p>
<blockquote>
<p><strong>About setting layer.trainable = False on a BatchNormalization layer:</strong><br>The meaning of setting layer.trainable = False is to freeze the layer, i.e. its internal state will not change during training: its trainable weights will not be updated during fit() or train_on_batch(), and its state updates will not be run.</p>
<p>Usually, this does not necessarily mean that the layer is run in inference mode (which is normally controlled by the training argument that can be passed when calling a layer). “Frozen state” and “inference mode” are two separate concepts.</p>
<p>However, in the case of the BatchNormalization layer, setting trainable = False on the layer means that the layer will be subsequently run in inference mode (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).</p>
<p>This behavior has been introduced in TensorFlow 2.0, in order to enable layer.trainable = False to produce the most commonly expected behavior in the convnet fine-tuning use case.</p>
</blockquote>
<p>儘管一般來說trainable=False只是代表凍結參數更新(Frozen state和inference mode是兩個不同的概念)，但對於BN來說則比較特殊，<strong>BN中設置trainable = False代表使用inference mode，也就是BN中的兩個參數alpha, beta會使用平均的值</strong>。</p>
<ul>
<li><strong>注意這是在TF2之後才引入的</strong>，對於TF1中，trainable=False只是凍結了參數，並不會變成inference mode(也就是不會使用平均的值帶入BN參數)</li>
</ul>
<p>至於trainable參數預設是什麼呢?</p>
<ul>
<li>在<a href="https://www.tensorflow.org/api_docs/python/tf/Variable" target="_blank" rel="noopener">tf.Variable</a>中寫到預設Variable的trainable都是True</li>
<li>在<a href="https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/engine/base_layer.py#L945" target="_blank" rel="noopener">tensorflow/tensorflow/python/keras/engine/base_layer.py</a>對於layer的預設也是True<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">             trainable=True,</span></span></span><br><span class="line"><span class="function"><span class="params">             name=None,</span></span></span><br><span class="line"><span class="function"><span class="params">             dtype=None,</span></span></span><br><span class="line"><span class="function"><span class="params">             dynamic=False,</span></span></span><br><span class="line"><span class="function"><span class="params">             **kwargs)</span>:</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>其他關於trainable參數要注意的地方</p>
<ul>
<li>對某一個layer設置trainable=True會連帶影響內部的所有layer的trainable參數</li>
<li>如果再compile()後才更改trainable參數，那要等到再次呼叫compile()才會更新</li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout" target="_blank" rel="noopener">tf.keras.layers.Dropout</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" target="_blank" rel="noopener">tf.keras.layers.BatchNormalization</a></li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/Variable" target="_blank" rel="noopener">tf.Variable</a></li>
</ul>

                <hr>
                <!-- Pager -->
                <ul class="pager">
    
    <li class="previous">
        <a href="/posts/3e428c8a/" data-toggle="tooltip" data-placement="top" title="[Tensorflow]從Pytorch到TF2的學習之路 - Custom Model & Custom training">&larr; Newer Post</a>
    </li>
    
    
    <li class="next">
        <a href="/posts/a151bfa2/" data-toggle="tooltip" data-placement="top" title="[論文速速讀]Network In Network">Older Post &rarr;</a>
    </li>
    
</ul>

                <!-- tip start -->
                

                
                <!-- tip end -->

                <!-- Sharing -->
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      
        <aside id="sidebar">
          <div id="toc" class="toc-article">
          <strong class="toc-title">Contents</strong>
          
            <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#前言"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">前言</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Dropout-training參數"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">Dropout: training參數</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#BatchNormalization-trainable參數"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">BatchNormalization: trainable參數</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#References"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">References</span></a></li></ol>
          
          </div>
        </aside>
      
    

        </div>
    </div>
</article>

	
    <!-- disqus embedded js code start (one page only need to embed once) -->	
    <script type="text/javascript">	
        /* * * CONFIGURATION VARIABLES * * */	
        var disqus_shortname = "meetonfriday";	
        var disqus_identifier = "https://meetonfriday.com/posts/877f4063/";	
        var disqus_url = "https://meetonfriday.com/posts/877f4063/";	
        (function() {	
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;	
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';	
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);	
        })();	
    </script>	
    <!-- disqus embedded js code start end -->	
    

    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                
                    <li>
                        <a target="_blank"  href="https://github.com/john850512">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank"  href="https://www.linkedin.com/in/john85051232">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/meetonfridayyy">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank"  href="https://mail.google.com/mail/?view=cm&fs=1&to=john85051232@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope-o fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; John 2025 
                    <br>
                    Powered by 
                    <a href="https://github.com/john850512/hexo-theme-jiji" target="_blank" rel="noopener">
                        <i>hexo-theme-jiji</i>
                    </a> | 
                    <iframe name="star" style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=john850512&repo=hexo-theme-jiji&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://meetonfriday.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<!--<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>-->
<script async src="//cdn.jsdelivr.net/npm/busuanzi@2.3.0"></script>




	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        
        <!-- background effects end -->
    
    
    <!-- background animation-->>
    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,e,a=0;a<r.length;a++)t=r[a],0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body>

</html>
