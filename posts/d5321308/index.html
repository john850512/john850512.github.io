<!DOCTYPE html>
<html lang="zh-TW">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="keyword"  content="programming, study, daily, entertainment">

    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="星期五。見面">
    <meta property="og:locale" content="zh-TW" />
    
    <meta property="og:title" content="[論文速速讀]Gradient Based Learning Applied to Document Recognition" />
    
    
    <meta property="og:description" content="CNN系列的開山始祖，LeNet(因為作者是Yann LeCun)，被應用在手寫辨識上，簡單的幾層Conv就可以在MNIST dataset上達到90%以上的Acc.。至今已經有兩萬以上的cite數量。基於gradient based learning的多層神經網路可以合成一個複雜的decision surface，使得在高維下也能夠很好地區分不同的pattern，例如手寫辨識，並且相較於傳統的技術，不需要太多的前處理就可以做得很好。這篇paper的貢獻可以簡述成下列幾項..." />
    <meta name="description" content="CNN系列的開山始祖，LeNet(因為作者是Yann LeCun)，被應用在手寫辨識上，簡單的幾層Conv就可以在MNIST dataset上達到90%以上的Acc.。至今已經有兩萬以上的cite數量。基於gradient based learning的多層神經網路可以合成一個複雜的decision surface，使得在高維下也能夠很好地區分不同的pattern，例如手寫辨識，並且相較於傳統的技術，不需要太多的前處理就可以做得很好。這篇paper的貢獻可以簡述成下列幾項...">
    
    
    <meta property="og:image" content="https://res.cloudinary.com/meet-on-friday/image/upload/v1594476939/blog_posts/%E6%93%B7%E5%8F%96_gqikcf.png" />
    

    <link rel="shortcut icon" href="/img/avatar.jpg">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          [論文速速讀]Gradient Based Learning Applied to Document Recognition - MeetonFriday
        
    </title>
    <!-- canonical -->
    
    
      <link rel="canonical" href="https://meetonfriday.com/posts/d5321308/">
    

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
<link rel="stylesheet" href="/css/dusign-dark.css">

    
<link rel="stylesheet" href="/css/dusign-common-dark.css">

    <!-- 
<link rel="stylesheet" href="/css/font-awesome.css">
 -->
    
<link rel="stylesheet" href="/css/toc.css">


    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <!-- <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css">
    
    <!-- Google Analytics -->
    
      <!-- <script>
          // dynamic User by Hux
          var _gaId = 'UA-163346001-1';
          var _gaDomain = 'auto';
      
          // Originial
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      
          ga('create', _gaId, _gaDomain);
          ga('send', 'pageview');
      </script> -->
      
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163346001-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
      
        gtag('config', 'UA-163346001-1');
      </script>
      
    <!-- google ad sense-->
    <script data-ad-client="ca-pub-9561340457908416" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="星期五。見面" type="application/atom+xml">
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.5)), url('/img/header_img/header-bg.jpg')
            
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#deep learning" title="deep learning">deep learning</a>
                            
                              <a class="tag" href="/tags/#paper" title="paper">paper</a>
                            
                        </div>
                        <h1>[論文速速讀]Gradient Based Learning Applied to Document Recognition</h1>
                        <h2 class="subheading"></h2>
                        <span class="meta">
                            Posted by John on
                            2020-07-12
                        </span>

                        
                            <div class="blank_box"></div>
                            <span class="meta">
                                Words <span class="post-count">2.8k</span> and
                                Reading Time <span class="post-count">10</span> Minutes
                            </span>
                            <div class="blank_box"></div>
                            <!-- 不蒜子统计 start -->
                            <span class="meta">
                                Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
                            </span>
                            <!-- 不蒜子统计 end -->
                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
        
            <div class="waveWrapper">
                <div class="wave wave_before" style="background-image: url('/img/wave-dark.png')"></div>
                <div class="wave wave_after" style="background-image: url('/img/wave-dark.png')"></div>
            </div>
        
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">星期五。見面</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/categories/">Categories</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/reading/">Reading</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

    
    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->

    
        
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">
        
    

                <p>〖想觀看更多中文論文導讀，至<a href="https://meetonfriday.com/posts/aa55d3f9/">[論文速速讀]系列文章介紹</a>可以看到目前已發布的所有文章！〗</p>
<p>paper: <a href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" target="_blank" rel="noopener">http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf</a></p>
<p><strong>CNN系列的開山始祖，LeNet(因為作者是Yann LeCun)</strong>，被應用在手寫辨識上，簡單的幾層Conv就可以在MNIST dataset上達到90%以上的Acc.。至今已經有兩萬以上的cite數量。</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><blockquote>
<p>Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient-based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing.</p>
</blockquote>
<p>基於gradient based learning的多層神經網路可以合成一個複雜的decision surface，使得在高維下也能夠很好地區分不同的pattern，例如手寫辨識，並且相較於傳統的技術，不需要太多的前處理就可以做得很好。</p>
<p>這篇paper的貢獻可以簡述成下列幾項:</p>
<ul>
<li>傳統的手寫辨識技術需要較多的前處理來提取特徵，透過自動學習來建立一個pattern recognition systems，降低前處理的步驟</li>
<li>提出了基於梯度學習的神經網路，並和當前手寫辨識的各類方法進行了比較</li>
<li>手寫辨識系統不只有辨識的部分，還包含了句子的分段，paper中也提出設計了一個通用化的架構: graph transformer networks (GTN’s)來做這件事。</li>
</ul>
<p>這篇文章中會聚焦在Deep learning的部分，關於後面的系統架構不會做太多的介紹，畢竟長達46頁看得頭很痛QQ</p>
<a id="more"></a>
<h2 id="Introudction"><a href="#Introudction" class="headerlink" title="Introudction"></a>Introudction</h2><p>傳統的pattern recognition通常分成兩個部分，因為data的變異性和豐富性使得無法完全透過手工來建立一個精準的辨識系統(要建立的feature太多了)，所以以前的方法會分成兩個部分(手工+自動)，大致上可以分成下圖兩個架構:</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1594297396/blog_posts/%E8%9E%A2%E5%B9%95%E5%BF%AB%E7%85%A7_2020-07-09_%E4%B8%8B%E5%8D%888.23.02_t14lck.png" alt=""></p>
<p>在這個架構中: </p>
<ol>
<li>透過一個人工建立的feature extraction module取得feature，這個module將raw data轉換成低維的feature vector或是symbols，使得這些feature可以<ul>
<li>很簡單的拿來進行匹配或比較的操作</li>
<li>對於不改變input性質的一些transformations和distortions具有不變性(比較robust)</li>
<li><strong>這個feature extractor也包含大量的先驗知識(也就是需要大量的domain knowledge)</strong>，並且是基於特定任務的(for special case)</li>
</ul>
</li>
<li>透過一個自動化的classifier module來進行分類</li>
</ol>
<blockquote>
<p>One of the main problems with this paper is that the recognition accuracy is larger determined by the ability of the designer to come up with an appropriate set of features .This turns out to be a daunting task which,unfortunately,must be redone for each new problem</p>
</blockquote>
<p>一個pattern recognition system的好壞很大一部分取決於前面的feature extractor，很直觀的，因為如果特徵取的不好，那在後面怎麼學也是學不好的。並且這個extractor還是case by case，所以很耗費大量的人力成本</p>
<p>傳統的技術上，特徵萃取的技術都被限制在低維度空間上進行操作才能有比較好的表現，但近幾年來這個限制卻被突破了，作者認為基於下面的原因:</p>
<ol>
<li>高效的設備成本越來越低，使得大家越來越有能力可以做一些運算量大的計算(例如numerical brute-force，其實就是在講Neural Network)</li>
<li>資料的取得更加容易，所以可以透過大量的real data來減少hand-crafted feature extraction</li>
<li>最重要的是，machine learning technique的興起使得可以處理高維度的資料</li>
</ol>
<h3 id="Leaning-from-Data"><a href="#Leaning-from-Data" class="headerlink" title="Leaning from Data"></a>Leaning from Data</h3><p>(看這段的時候好像再重新學習deep learning的基礎xD)</p>
<p>近期(注意這篇paper是1998年喔，大概是我兩歲的時候)一個成功的automatic machine learning技術，叫做”numerical”或”gradient-based learning”，對於第$p$個input pattern $Z^{p}$，給予一組權重$W$，使用機器學習的方式$F(\cdot)$可以學到一個predict $Y^{p}$，公式如下:<script type="math/tex">Y^{p}=F(Z^{p}, W)</script></p>
<p>然後我們可以去計算這個prediction跟ground truth $D^{p}$的差異:</p>
<script type="math/tex; mode=display">
E^{p}=\mathcal{D}\left(D^{p}, F\left(W, Z^{p}\right)\right) \\
E_{t r a i n}=\frac{1}{P} \sum_{n-1}^{P} E^{p}</script><p>而一種最佳化方法就是<strong>找到一組$W$使得minimize $E_{t r a i n}$</strong>，這個performance通常會在獨立於training set的另一組data上來評估，也就是testing set。一些研究發現testing error和train error之間的差異(gap)會近似(這一項有點眼熟，好像就是VC bound? h好像就是VC dimension?)<br>(VC bound的部分推薦林軒田教授的機器學習課程，雖然很數學，不過稱過一次可以很清楚理解，讚讚)</p>
<script type="math/tex; mode=display">
E_{\text {test}}-E_{\text {train}}=k(h / P)^{\alpha}</script><p>跟在介紹VC bound時一樣，這個公式可以幫助我們理解怎樣對於machine learning是有幫助的:</p>
<ul>
<li>當traning samples增加的時候這個gap會降低</li>
<li>當訓練複雜度h增加的時候， E_{train}會降低<ul>
<li>所以這裡會有一個trade-off，在gap和$E_train$之間</li>
</ul>
</li>
</ul>
<p>如何想辦法降低gap的同時也降低training error，這類研究稱之structural risk minimization</p>
<ul>
<li>通常會透過加一個regularization function來trade-off模型的複雜度</li>
</ul>
<h3 id="Gradient-Based-Learning"><a href="#Gradient-Based-Learning" class="headerlink" title="Gradient Based Learning"></a>Gradient Based Learning</h3><p>更新權重的公式，用到微積分的chain rule</p>
<script type="math/tex; mode=display">
W_{k}=W_{k-1}-\epsilon \frac{\partial E(W)}{\partial W}</script><p>或用SGD</p>
<script type="math/tex; mode=display">
W_{k}=W_{k-1}-\epsilon \frac{\partial E^{p_{k}}(W)}{\partial W}</script><p>這個都聽到爛掉不想看惹，跳過，有興趣再自己去補。</p>
<h3 id="Gradient-Back-Propagation"><a href="#Gradient-Back-Propagation" class="headerlink" title="Gradient Back-Propagation"></a>Gradient Back-Propagation</h3><p>論文中提到，近年來gradient based learning的興起和下面幾件事情有關:</p>
<ol>
<li>在高維度中，loss function的local minima並不是實務上的問題<ul>
<li><strong>在高維度中，其實收斂到鞍點的機率遠大於收斂到局部最小值</strong>，有興趣的可以參考<a href="https://www.zhihu.com/question/68109802" target="_blank" rel="noopener">梯度下降法的神经网络容易收敛到局部最优，为什么应用广泛？</a> </li>
</ul>
</li>
<li>透過back propagation，可以在多層非線性系統計算gradient</li>
<li>back propagetion搭配神經網路可以學習到複雜的任務</li>
</ol>
<h3 id="Learning-in-Real-Handwriting-Recognition-Systems"><a href="#Learning-in-Real-Handwriting-Recognition-Systems" class="headerlink" title="Learning in Real Handwriting Recognition Systems"></a>Learning in Real Handwriting Recognition Systems</h3><p>跟Deep Learning無關，跳過</p>
<h3 id="Global-ly-Trainable-Systems"><a href="#Global-ly-Trainable-Systems" class="headerlink" title="Global ly Trainable Systems"></a>Global ly Trainable Systems</h3><p>跳過跳過</p>
<h2 id="Convolutional-Neural-Network-for-Isolated-Character-Recognition"><a href="#Convolutional-Neural-Network-for-Isolated-Character-Recognition" class="headerlink" title="Convolutional Neural Network for Isolated Character Recognition"></a>Convolutional Neural Network for Isolated Character Recognition</h2><p>傳統的方式會先透過人工的一些方法萃取出feature然後去訓練，不過如果想要讓模型自己學到這些feature的話該怎麼辦？</p>
<p>論文中提到了幾個困難點:</p>
<ol>
<li>image size過大，如果一開始就用FC(Fully Connected Layer)會造成參數過多</li>
<li><strong>FC這種沒有結構的網路並不具備平移、縮放等不變性(invariance with respect to translations, or local distortions of the inputs)</strong>，也就是說如果圖片有經過一些調整轉換、放大縮小、位移，則FC學到的特徵會完全不同。理論上一個非常大的FC搭配更多的data可以考慮這些狀況(使得所有case都可以被FC學到)，不過這不make sense<ul>
<li>而CNN具備了平移不變性(shift invariance)，所以很適用在圖片上的相關任務</li>
</ul>
</li>
<li>FC忽略了input的拓墣結構，<strong>對於圖片這種二維結構，相鄰的pixel有很大的相關性</strong>，不過這在FC中都只是彼此獨立的，甚至順序還可以互相對調而不影響結果。<ul>
<li>在CNN中則是可以學習到一些local feature</li>
</ul>
</li>
</ol>
<h3 id="Convolutional-Networks"><a href="#Convolutional-Networks" class="headerlink" title="Convolutional Networks"></a>Convolutional Networks</h3><p>CNN的三個重要概念:</p>
<ul>
<li><strong>local receptive</strong></li>
<li><strong>shared weights(weight replication)</strong></li>
<li><strong>spatial(temporal) sub-sampling</strong></li>
</ul>
<h4 id="local-receptive"><a href="#local-receptive" class="headerlink" title="local receptive"></a>local receptive</h4><p>相較於全連接層的感受範圍是整張圖片，一點點圖片的變化就會影響萃取的feature。使用CNN的kernel(或是filter)可以做到局部感受野，使得神經網路能夠提取一些局部特徵(邊緣、角)，並交給下一層合成更高級的特徵。</p>
<h4 id="shared-weights"><a href="#shared-weights" class="headerlink" title="shared weights"></a>shared weights</h4><p>由於圖片可能會位移或是形變，在做convolution時使用了具有相同權重的kernel不只可以降低計算量，也可以想成<strong>在不同圖片上使用相同的局部感受野萃取相同的特徵，這樣的話物體在圖片的哪個位置就相對沒那麼重要了</strong>。</p>
<p>shared weights和local  receptive是CNN對位移和形變robust的原因(shift-invariance)</p>
<h4 id="spatial-temporal-sub-sampling"><a href="#spatial-temporal-sub-sampling" class="headerlink" title="spatial(temporal) sub-sampling"></a>spatial(temporal) sub-sampling</h4><p>一但透過convolution得到feature map，特徵的位置就不是那麼重要了，特徵跟特徵之間的相對位置才是我們需要關注的。<strong>down-sampling的方式可以降低特徵在圖片中位置的精度，也可以使得CNN更加robust</strong>，這使得CNN對於物件在圖片中的什麼位置上影響比較相對較小</p>
<h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p>最後來看一下LeNet的架構:</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1594476939/blog_posts/%E6%93%B7%E5%8F%96_gqikcf.png" alt=""></p>
<p>比較特別的地方稍微提一下:</p>
<h4 id="C3的Conv-layer"><a href="#C3的Conv-layer" class="headerlink" title="C3的Conv layer"></a>C3的Conv layer</h4><p>C3的Conv layer不是現在一般的Conv，而是將前一層(S2)的數個output，也就是feature map，做convolution，對應的關係如下表，列代表每一個feature map，行代表這一個convolution使用到了哪幾個feature map<br><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1594477290/blog_posts/%E6%93%B7%E5%8F%96_cegd4i.png" alt=""></p>
<p>作者認為這樣的好處在於: </p>
<ul>
<li>降低參數使用量 </li>
<li>利用對稱的連接方式學到不同的特徵</li>
</ul>
<p>不過現在CNN幾乎沒人這樣用了…</p>
<h4 id="F6為啥是84"><a href="#F6為啥是84" class="headerlink" title="F6為啥是84?"></a>F6為啥是84?</h4><p>其實這也沒啥，神經網路數字想給多少就給多少，只要接得起來就好。不過為啥是84，難道LeCun也會通靈?</p>
<p>F6取84的原因是因為: 對應到ASCII的bitmap，如下圖每一個符號都是7 * 12的bitmap，所以這層的FC output是84<br><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1594477768/blog_posts/%E6%93%B7%E5%8F%96_uwqhhi.png" alt=""></p>
<p>你說阿為啥要讓他等於ASCII的bitmap? 因為在原始LeNet中，output layer的計算方式是用到Euclidean Radial Basis Function ( RBF )來計算每個類別的值:</p>
<script type="math/tex; mode=display">y_{i}=\sum_{j}\left(x_{j}-w_{ij}\right)^{2}</script><p>$x$是output layer的輸出(共10個)，$i$是類別(0-9)，$j$是bitmap中的每一個pixel(0-83)，所以RBF的值越接近0代表預測出來的圖片和ASCII該類圖片的bitmap越相近。</p>
<h4 id="loss-function"><a href="#loss-function" class="headerlink" title="loss function"></a>loss function</h4><p>使用MLE(Maximum Likelihood Estimation)，希望訓所有訓練資料預測正確的「正確類別」 RBF 值之平均越小越好。</p>
<p>不過單純這樣設計會有一些問題，所以又補上了Maximum a posteriori(MAP)進去，細節這裡就不講了，因為後續CNN其實也不是用這個方式來設計。不過有興趣的可以參考<a href="https://allen108108.github.io/blog/2019/10/04/[%E8%AB%96%E6%96%87]%20Gradient-Based%20Learning%20Applied%20to%20Document%20Recognition/" target="_blank" rel="noopener">[ 論文 ] Gradient-Based Learning Applied to Document Recognition</a>或<a href="https://hackmd.io/@DanielChen/rka5m35NX?type=view" target="_blank" rel="noopener">Gradient-Based Learning Applied to Document Recognition</a>這篇，覺得講得非常仔細。</p>
<p>不過後來的model也都是用單純的cross entropy來training…</p>
<h2 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h2><p>原本是為了重看所有的CNN系列論文才開始看這篇，結果就發現第一篇居然給我有46頁讓我很無語(雖然最後也沒有全看完)。</p>
<p>重看這篇有總在複習Deep Learning跟CNN的感覺，主要更加了解CNN的三個特性(local receptive, shared weights, spatial sub-sampling)。以這篇為基礎，之後會開始看其他後續的CNN paper。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a href="https://blog.csdn.net/sunshine_010/article/details/79876255" target="_blank" rel="noopener">论文阅读笔记（一）：Gradient-Based Learning Applied to Document Recognition ( LeNet )</a></li>
<li><a href="https://allen108108.github.io/blog/2019/10/04/[%E8%AB%96%E6%96%87]%20Gradient-Based%20Learning%20Applied%20to%20Document%20Recognition/" target="_blank" rel="noopener">[ 論文 ] Gradient-Based Learning Applied to Document Recognition</a></li>
<li><a href="https://www.zhihu.com/question/68109802" target="_blank" rel="noopener">梯度下降法的神经网络容易收敛到局部最优，为什么应用广泛？</a></li>
<li><a href="https://blog.csdn.net/qianqing13579/article/details/71076261" target="_blank" rel="noopener">LeNet论文的翻译与CNN三大核心思想的解读</a></li>
<li><a href="https://hackmd.io/@DanielChen/rka5m35NX?type=view" target="_blank" rel="noopener">Gradient-Based Learning Applied to Document Recognition</a></li>
</ul>

                <hr>
                <!-- Pager -->
                <ul class="pager">
    
    <li class="previous">
        <a href="/posts/e54c12ea/" data-toggle="tooltip" data-placement="top" title="[論文速速讀]ImageNet Classification with Deep Convolutional Neural Networks">&larr; Newer Post</a>
    </li>
    
    
    <li class="next">
        <a href="/posts/aa55d3f9/" data-toggle="tooltip" data-placement="top" title="[論文速速讀]系列文章介紹">Older Post &rarr;</a>
    </li>
    
</ul>

                <!-- tip start -->
                

                
                <!-- tip end -->

                <!-- Sharing -->
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      
        <aside id="sidebar">
          <div id="toc" class="toc-article">
          <strong class="toc-title">Contents</strong>
          
            <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Abstract"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">Abstract</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Introudction"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">Introudction</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Leaning-from-Data"><span class="toc-nav-number">2.1.</span> <span class="toc-nav-text">Leaning from Data</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Gradient-Based-Learning"><span class="toc-nav-number">2.2.</span> <span class="toc-nav-text">Gradient Based Learning</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Gradient-Back-Propagation"><span class="toc-nav-number">2.3.</span> <span class="toc-nav-text">Gradient Back-Propagation</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Learning-in-Real-Handwriting-Recognition-Systems"><span class="toc-nav-number">2.4.</span> <span class="toc-nav-text">Learning in Real Handwriting Recognition Systems</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Global-ly-Trainable-Systems"><span class="toc-nav-number">2.5.</span> <span class="toc-nav-text">Global ly Trainable Systems</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Convolutional-Neural-Network-for-Isolated-Character-Recognition"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">Convolutional Neural Network for Isolated Character Recognition</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Convolutional-Networks"><span class="toc-nav-number">3.1.</span> <span class="toc-nav-text">Convolutional Networks</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#local-receptive"><span class="toc-nav-number">3.1.1.</span> <span class="toc-nav-text">local receptive</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#shared-weights"><span class="toc-nav-number">3.1.2.</span> <span class="toc-nav-text">shared weights</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#spatial-temporal-sub-sampling"><span class="toc-nav-number">3.1.3.</span> <span class="toc-nav-text">spatial(temporal) sub-sampling</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#LeNet-5"><span class="toc-nav-number">3.2.</span> <span class="toc-nav-text">LeNet-5</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#C3的Conv-layer"><span class="toc-nav-number">3.2.1.</span> <span class="toc-nav-text">C3的Conv layer</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#F6為啥是84"><span class="toc-nav-number">3.2.2.</span> <span class="toc-nav-text">F6為啥是84?</span></a></li><li class="toc-nav-item toc-nav-level-4"><a class="toc-nav-link" href="#loss-function"><span class="toc-nav-number">3.2.3.</span> <span class="toc-nav-text">loss function</span></a></li></ol></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#結論"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">結論</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#References"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">References</span></a></li></ol>
          
          </div>
        </aside>
      
    

        </div>
    </div>
</article>

	
    <!-- disqus embedded js code start (one page only need to embed once) -->	
    <script type="text/javascript">	
        /* * * CONFIGURATION VARIABLES * * */	
        var disqus_shortname = "meetonfriday";	
        var disqus_identifier = "https://meetonfriday.com/posts/d5321308/";	
        var disqus_url = "https://meetonfriday.com/posts/d5321308/";	
        (function() {	
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;	
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';	
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);	
        })();	
    </script>	
    <!-- disqus embedded js code start end -->	
    

    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                
                    <li>
                        <a target="_blank"  href="https://github.com/john850512">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank"  href="https://www.linkedin.com/in/john85051232">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/meetonfridayyy">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank"  href="https://mail.google.com/mail/?view=cm&fs=1&to=john85051232@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope-o fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; John 2025 
                    <br>
                    Powered by 
                    <a href="https://github.com/john850512/hexo-theme-jiji" target="_blank" rel="noopener">
                        <i>hexo-theme-jiji</i>
                    </a> | 
                    <iframe name="star" style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=john850512&repo=hexo-theme-jiji&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://meetonfriday.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<!--<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>-->
<script async src="//cdn.jsdelivr.net/npm/busuanzi@2.3.0"></script>




	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        
        <!-- background effects end -->
    
    
    <!-- background animation-->>
    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,e,a=0;a<r.length;a++)t=r[a],0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body>

</html>
