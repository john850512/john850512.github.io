<!DOCTYPE html>
<html lang="zh-TW">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="keyword"  content="programming, study, daily, entertainment">

    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="星期五。見面">
    <meta property="og:locale" content="zh-TW" />
    
    <meta property="og:title" content="[論文速速讀]Going deeper with convolutions" />
    
    
    <meta property="og:description" content="GoogLeNet，Google 2015年在CVPR發表的paper，也是ILSVRC 2014的冠軍(Classification &amp; Detection)，會這樣取名是為了致敬LeNet，所以特地把google的l給大寫了。Google透過提出了Inception的深度神經網路結構，主要改進了網路內計算資源的使用效率，並能在計算資源固定下能夠訓練得更深更廣。" />
    <meta name="description" content="GoogLeNet，Google 2015年在CVPR發表的paper，也是ILSVRC 2014的冠軍(Classification &amp; Detection)，會這樣取名是為了致敬LeNet，所以特地把google的l給大寫了。Google透過提出了Inception的深度神經網路結構，主要改進了網路內計算資源的使用效率，並能在計算資源固定下能夠訓練得更深更廣。">
    
    
    <meta property="og:image" content="https://res.cloudinary.com/meet-on-friday/image/upload/v1595629450/blog_posts/%E6%93%B7%E5%8F%96_epvtfg.png" />
    

    <link rel="shortcut icon" href="/img/avatar.jpg">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          [論文速速讀]Going deeper with convolutions - MeetonFriday
        
    </title>
    <!-- canonical -->
    
    
      <link rel="canonical" href="https://meetonfriday.com/posts/263e065d/">
    

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
<link rel="stylesheet" href="/css/dusign-dark.css">

    
<link rel="stylesheet" href="/css/dusign-common-dark.css">

    <!-- 
<link rel="stylesheet" href="/css/font-awesome.css">
 -->
    
<link rel="stylesheet" href="/css/toc.css">


    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <!-- <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">-->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css">
    
    <!-- Google Analytics -->
    
      <!-- <script>
          // dynamic User by Hux
          var _gaId = 'UA-163346001-1';
          var _gaDomain = 'auto';
      
          // Originial
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      
          ga('create', _gaId, _gaDomain);
          ga('send', 'pageview');
      </script> -->
      
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163346001-1"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
      
        gtag('config', 'UA-163346001-1');
      </script>
      
    <!-- google ad sense-->
    <script data-ad-client="ca-pub-9561340457908416" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/atom.xml" title="星期五。見面" type="application/atom+xml">
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.5)), url('/img/header_img/header-bg.jpg')
            
        
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#deep learning" title="deep learning">deep learning</a>
                            
                              <a class="tag" href="/tags/#paper" title="paper">paper</a>
                            
                        </div>
                        <h1>[論文速速讀]Going deeper with convolutions</h1>
                        <h2 class="subheading"></h2>
                        <span class="meta">
                            Posted by John on
                            2020-07-25
                        </span>

                        
                            <div class="blank_box"></div>
                            <span class="meta">
                                Words <span class="post-count">3.9k</span> and
                                Reading Time <span class="post-count">14</span> Minutes
                            </span>
                            <div class="blank_box"></div>
                            <!-- 不蒜子统计 start -->
                            <span class="meta">
                                Viewed <span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span> Times
                            </span>
                            <!-- 不蒜子统计 end -->
                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
        
            <div class="waveWrapper">
                <div class="wave wave_before" style="background-image: url('/img/wave-dark.png')"></div>
                <div class="wave wave_after" style="background-image: url('/img/wave-dark.png')"></div>
            </div>
        
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">星期五。見面</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/categories/">Categories</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/reading/">Reading</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

    
    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->

    
        
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">
        
    

                <p>〖想觀看更多中文論文導讀，至<a href="https://meetonfriday.com/posts/aa55d3f9/">[論文速速讀]系列文章介紹</a>可以看到目前已發布的所有文章！〗</p>
<p>paper: <a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.4842.pdf</a></p>
<p><strong>GoogLeNet，Google 2015年在CVPR發表的paper，也是ILSVRC 2014的冠軍</strong>(Classification &amp; Detection)，會這樣取名是為了致敬LeNet，所以特地把google的l給大寫了。</p>
<p>這篇介紹會聚焦在Classification和模型的部分，所以對於Detection會跳過或快速帶過，有興趣可以去看原文。</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><blockquote>
<p>The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant.</p>
</blockquote>
<p>ILSVRC 2014的冠軍，恭喜恭喜( ﾟ∀ﾟ)o彡ﾟ</p>
<p>Google透過提出了Inception的深度神經網路結構，主要改進了網路內計算資源的使用效率，並能在計算資源固定下能夠訓練得更深更廣。</p>
<a id="more"></a>
<blockquote>
<p>To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing</p>
</blockquote>
<p>此外還遵循了<strong>Hebbian原則和多尺度的處理</strong>的想法來設計..</p>
<p>好喔…所以我說…Hebbian原則是蝦咪挖歌?? </p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote>
<p>Our GoogLeNet submission to ILSVRC 2014 actually uses 12× fewer parameters than the winning architecture of Krizhevsky et al [9] from two years ago, while being significantly more accurate.</p>
</blockquote>
<p>首先，GoogLeNet使用的參數量只有AlexNet的1/12倍，但卻有著更好的準確度。</p>
<blockquote>
<p>In this paper, we will focus on an efficient deep neural network architecture for computer vision, codenamed Inception, which derives its name from the Network in network paper by Lin et al [12] in conjunction with the famous “we need to go deeper” internet meme [1].</p>
</blockquote>
<p>Inception結構是從Network in Network, NIN這篇論文發展而來，然後名字的由來來自NIN中的meme “<strong>we need to go deeper</strong>“…棒喔，還cite一個meme</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1595358824/blog_posts/a88_pc8dhu.jpg" alt=""></p>
<p>(20200814更新)NIN的文章出來啦! 有興趣的可以看這篇: <a href="https://meetonfriday.com/posts/a151bfa2">[論文速速讀]Network In Network</a></p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><ol>
<li>介紹了CNN的background</li>
<li>受到靈長類神經模型的啟發，Serre et al，使用了不同大小的Gabor filter來學習不同尺度的特徵，這類似於Inception的做法，但不同的是Inception的所有filter都是可以被學習的</li>
<li>在NIN這篇論文中，透過了1x1的Conv來增加模型的表達能力和計算複雜度。<strong>在Inception中1x1 Conv最主要被用來做dimension reduction以降低記算複雜度，這使得模型可以在不增加計算複雜度的情況下增加寬度</strong>(變胖了!)</li>
<li>這是在講Detection的部分，R-CNN中將檢測任務分成了兩個階段: Region Proposal和Classification。GoogLeNet也用到了類似的方法並加以改良，然後得到了較好的結果。</li>
</ol>
<h2 id="Motivation-and-High-Level-Considerations"><a href="#Motivation-and-High-Level-Considerations" class="headerlink" title="Motivation and High Level Considerations"></a>Motivation and High Level Considerations</h2><p>其實單看GoogLeNet架構並不難理解，但如果要試著去理解這個設計背後的動機和考量並沒有那麼簡單。這邊就從原文的角度出發來看一下設計背後的思維:</p>
<p>提升神經網路效果最直覺的方法就是<strong>增加網路的深度跟寬度</strong>，暴力但有效，但這樣有兩個主要的缺點:</p>
<ul>
<li><strong>在數據不夠大量的時候，模型參數過多往往容易overfitting</strong><ul>
<li>你說那為何不給多點數據就好了? 孩子你去跟你老闆這樣講講看啊</li>
<li>在論文中還特地給了一張圖片來告訴你如果對於一些需要精細標記的類別，標記是一件多麼費工的事情</li>
</ul>
</li>
<li><strong>計算資源的問題，模型越大計算資源越大，而得到的效益往往不成正比</strong>，如果學到了一堆拉基(例如weight都是0)那根本就是在浪費資源</li>
</ul>
<blockquote>
<p>The fundamental way of solving both issues would be by ultimately moving from fully connected to sparsely connected architectures, even inside the convolutions.</p>
</blockquote>
<p>解決上述兩個議題的方式是可以<strong>建立一個稀疏的神經網路結構</strong>，也就是用稀疏的層取代全連接層以及Conv層(為什麼Conv不是稀疏層後面會說)</p>
<p>根據Arora的研究: 如果可以透過一個大且稀疏的神經網路結構來表示一個dataset的機率分佈，那麼可以透過逐層分析然後將相關性高的元素群聚起來，進而去找到一個最優的網路拓樸結構(optimal network topology)，這個研究與著名的Hebbian principle不謀而合，Hebbian principle說到: “neurons that fire together, wire together”</p>
<blockquote>
<p>Most current vision oriented machine learning systems utilize sparsity in the spatial domain just by the virtue of employing convolutions. However, convolutions are implemented as collections of dense connections to the patches in the earlier layer.</p>
</blockquote>
<p><strong>卷積其實就是在空間域上實現了稀疏性的一種操作</strong>，圖片中相鄰的點其實相關性最高，而這些相關性高的點透過卷積給群聚起來了，是不是跟上面的研究很像呢，所以卷積是符合Hebbian principle的。</p>
<p>但卷積的操作本身還是密集連接而不是稀疏連接，因為卷積本質上還是上一層的每個neuron和這一層的每個neuron去逐點計算(早期在LeNet的時候對於卷積有隨機和稀疏連接的設計以打破對稱性(參見<a href="https://meetonfriday.com/posts/d5321308/">[論文速速讀]Gradient Based Learning Applied to Document Recognition</a>中C3的Conv layer)，但後來AlexNet又改回一般的全連接卷積，由於這樣能夠更好的優化跟平行計算)。</p>
<p>那重點來了，既然稀疏的神經網路結構無法建立，那要怎麼解決原本的議題呢？</p>
<blockquote>
<p>This raises the question whether there is any hope for a next, intermediate step: an architecture that makes use of the extra sparsity, even at filter level, as suggested by the theory, but exploits our current hardware by utilizing computations on dense matrices. </p>
</blockquote>
<p>既然無法達到真正完整的稀疏網路結構，那就退而求其次，<strong>在filter level上來實踐稀疏性，期望能逼近稀疏網路結構的效果</strong></p>
<ul>
<li>利用filter level的稀疏能力</li>
<li>但層和層之間還是全連接的，如此仍舊確保了計算上的效率</li>
</ul>
<p>filter level是什麼意思呢，看了幾篇文章後我覺得<a href="https://zhuanlan.zhihu.com/p/32702031" target="_blank" rel="noopener">深入理解GoogLeNet结构（原创）</a>講的是我比較能夠接受的講法，以下引用該篇文章的解釋:</p>
<blockquote>
<p>这个原理应用到inception上就是要在特征维度上进行分解！传统的卷积层的输入数据只和一种尺度（比如3x3）的卷积核进行卷积，输出固定维度（比如256个特征）的数据，所有256个输出特征基本上是均匀分布在3x3尺度范围上，这可以理解成输出了一个稀疏分布的特征集；而inception模块在多个尺度上提取特征（比如1x1，3x3，5x5），输出的256个特征就不再是均匀分布，而是相关性强的特征聚集在一起（比如1x1的的96个特征聚集在一起，3x3的96个特征聚集在一起，5x5的64个特征聚集在一起），这可以理解成多个密集分布的子特征集。这样的特征集中因为相关性较强的特征聚集在了一起，不相关的非关键特征就被弱化，同样是输出256个特征，inception方法输出的特征“冗余”的信息较少。用这样的“纯”的特征集层层传递最后作为反向计算的输入，自然收敛的速度更快。</p>
</blockquote>
<p>也就是將特徵透過不同size的kernel來萃取再合併起來，使得高相關性的特徵都能夠被群聚在一起(1x1一群、3x3一群、5x5一群)，這也符合了Hebbian principle</p>
<p>最後paper也提到，儘管發現Inception可以提升結果，但究竟是不是因為這樣的架構設計才造成提升的還有待實驗證實。</p>
<p>…歐這一章節好難懂喔，沒看論文前明明覺得概念其實不難，仔細讀論文才知道背後的意涵這麼複雜= =</p>
<h2 id="Architectural-Details"><a href="#Architectural-Details" class="headerlink" title="Architectural Details"></a>Architectural Details</h2><blockquote>
<p>The main idea of the Inception architecture is based on finding out how an optimal local sparse structure in a convolutional vision network can be approximated and covered by readily available dense components.</p>
</blockquote>
<p>所以Inception架構的目的就是要找出一個局部最佳的稀疏結構，並且這結構可以簡單的透過全連接串起來。</p>
<h3 id="naive-version"><a href="#naive-version" class="headerlink" title="naive version"></a>naive version</h3><ul>
<li>在CNN淺層的時候會學到一些初階的局部特徵，這些特徵通常都集中在某些的區域且相關性較高，而我們可以透過1x1 Conv將他們涵蓋到下一層<ul>
<li>可以想成圖片同個位置上不同channel的相關性較高，而我們可以使用1x1 Conv給涵蓋著</li>
</ul>
</li>
<li>此外，有些稀疏的特徵群也可以被kernel size較大的Conv給涵蓋到，並且kernel size越大涵蓋的範圍也理當越大，所以也加入了3x3 Conv和5x5 Conv</li>
<li>使用1x1, 3x3, 5x5的Conv是為了設計上的方便性，因為在固定stride=1的情況下，我們只要設定pad=0,1,2就可以得到相同size的輸出，輕鬆地解決了patch alignment的問題</li>
<li>並且隨著Inception在模型中越深層，應該會學到越高階的抽象特徵，所以3x3和5x5 Conv的數量會隨著層數越深而提高，而學習局部特徵的1x1 Conv數量則會越來越少</li>
<li>此外發現，Pooling也有助於提升結果，所以再加入Pooling進來</li>
</ul>
<p>最後naive version架構如下:<br><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1595582404/blog_posts/%E8%9E%A2%E5%B9%95%E5%BF%AB%E7%85%A7_2020-07-24_%E4%B8%8B%E5%8D%885.19.49_fwkfbh.png" alt=""></p>
<p>這個架構的問題是，即使做到了局部稀疏的架構，但在性能上非常的差，因為同時使用了不同的scale的Conv又使用了Pooling，可想而知最後合併得到的filter數量(或者說dimension)會非常的大，所以有了第二個版本。</p>
<h3 id="Inception-module-with-dimension-reductions"><a href="#Inception-module-with-dimension-reductions" class="headerlink" title="Inception module with dimension reductions"></a>Inception module with dimension reductions</h3><p>很直觀的想法就是<strong>在計算量大的地方之前使用1x1 Conv來做降維</strong>，由於dimensional embeddings的成功，我們仍然能夠在維度減少的情況下保留大部分的資訊。</p>
<blockquote>
<p> However, embeddings represent information in a dense, compressed form and compressed information is harder to model. We would like to keep our representation sparse at most places (as required by the conditions of [2]) and compress the signals only whenever they have to be aggregated en masse.</p>
</blockquote>
<p>但是根據Arora的研究，所有的地方都降維也不是明智之舉，作者仍然想要讓整體的網路結構還是應該保持稀疏，所以只在需要被3x3和5x5之前、和max pooling之後使用。</p>
<ul>
<li>1x1 Conv後面是接著ReLU的，使得能夠有更多的非線性變換</li>
<li>透過1x1 Conv降維使得儘管卷積的操作變多了，但整體的計算量並不會超出太多</li>
</ul>
<p>最後架構如下:</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1595626451/blog_posts/%E8%9E%A2%E5%B9%95%E5%BF%AB%E7%85%A7_2020-07-25_%E4%B8%8A%E5%8D%885.33.00_u0bj0m.png" alt=""></p>
<p>由於memory考量，作者他們只在GoogLeNet中後半加入Inception，前幾層還是按照CNN的一般建模方式來設計。</p>
<h3 id="直覺上的設計考量"><a href="#直覺上的設計考量" class="headerlink" title="直覺上的設計考量"></a>直覺上的設計考量</h3><p>前面的看不懂嗎，那看從這節開始看就好了(?)</p>
<p>在Motivation中提到作者最原始的設計出發點是想要設計一個稀疏的局部最優網路結構，但其實Inception有個大家應該都比較熟悉的、也比較直覺的設計思維:</p>
<ol>
<li><strong>多尺度提取特徵</strong>: 透過1x1, 3x3, 5x5的Conv進行卷積，使得在下一層能夠從不同尺度上進行特徵提取</li>
<li><strong>架構要怎麼設計，不如讓模型自己決定</strong>: 大家一定想過如果要自己設計一個CNN模型，那要怎麼去設計Conv層和Pooling層的搭配呢? 那不如讓模型自己決定吧! 同時給出不同的卷積和Pooling讓模型自己去訓練，然後模型在更新的過程中就自然的會給予他認為比較好的操作較大的權重</li>
</ol>
<h3 id="1x1-Conv是如何降低計算量的"><a href="#1x1-Conv是如何降低計算量的" class="headerlink" title="1x1 Conv是如何降低計算量的?"></a>1x1 Conv是如何降低計算量的?</h3><p>1x1的Conv就是一個kernel(或者稱filter)掃過去，那到底要如何降低計算量?</p>
<p>關鍵在於該kernel的channel(或者說dimension)的數量是可以控制的，所以只要output dimension參數設置的比原本前一層Conv小就可以做降維，反之也可以提升維度。</p>
<ul>
<li>在這操作中，可以想成1x1 Conv整合了同個位置不同channel之間的訊息</li>
</ul>
<p>舉個例子: </p>
<p>假設上一層的輸出是(100, 100, 128)</p>
<p>經過一個5x5的Conv(有256個filter, stride=1, padding=2, 如此的設置保持了output size大小不變)，我們可以得到的輸出為(100, 100, 256)</p>
<p>在這個例子下，卷積的參數為128 x 5 x 5 x 256 = 819200 (不考慮bias)</p>
<ul>
<li>input channel x kernel size x output channel</li>
<li>想了解更多如何計算參數量可以參考我以前的文章: <a href="https://meetonfriday.com/posts/4647b68d/">[DL]Calculate Parameter Numbers of MLP &amp; CNN</a></li>
</ul>
<p>不過如果中間先經過了1x1 Conv降維(假設32個filter)，在接5x5的Conv，我們的參數量就會是: 128 x 1 x 1 x 32 + 32 x 5 x 5 x 256 = 208896</p>
<ul>
<li>可以看到參數量少了4倍，而最後的輸出仍然是(100, 100, 256)</li>
</ul>
<p>那中間經過降維會不會影響模型精度?<br>其實模型在高維度中很容易找到一個hyperplane去fit我們的data，所以適當的降維其實不太會降低我們的模型結果，可以想成將原本較分散的資訊量都集中在這些維度上了(當然你也不能降維的太誇張啦)</p>
<h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>慢慢看論文好累啊，我要快速<del>飆車</del>帶過了</p>
<p>最後的架構如下，我把架構圖壓縮倒過來放不然太大了，看的再去paper看原圖ˊ＿&gt;ˋ</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1595629450/blog_posts/%E6%93%B7%E5%8F%96_epvtfg.png" alt=""></p>
<p>最後對GoogLeNet稍微整理一下:</p>
<ol>
<li>總共27層</li>
<li><strong>在分類前使用NIN的Gobal Average Pooling(GAP)</strong><ul>
<li>GAP不需要參數，並且能有更好的representation</li>
<li>實驗結果顯示比用FC layer提升了1%的Acc</li>
</ul>
</li>
<li>還是有使用dropout的regularization技術</li>
<li>加入了兩個auxiliary classifiers: 隨著網路變深，可能會產生gradient vanishing的問題。於是想透過中間層來幫助預測，在訓練的過程中會透過給予auxiliary classifiers權重的方式來一起去分類<ul>
<li>但是在預測的時候則不會使用 </li>
</ul>
</li>
</ol>
<h3 id="Training-Methodology"><a href="#Training-Methodology" class="headerlink" title="Training Methodology"></a>Training Methodology</h3><p>跳過，覺得比較沒有重要的，有興趣自己看原文</p>
<h3 id="ILSVRC-2014-Classification-Challenge-Setup-and-Results"><a href="#ILSVRC-2014-Classification-Challenge-Setup-and-Results" class="headerlink" title="ILSVRC 2014 Classification Challenge Setup and Results"></a>ILSVRC 2014 Classification Challenge Setup and Results</h3><p>訓練了7個GoogLeNet來做Ensemble，最後結果如下:</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1595630447/blog_posts/%E8%9E%A2%E5%B9%95%E5%BF%AB%E7%85%A7_2020-07-25_%E4%B8%8A%E5%8D%886.40.20_s0om7e.png" alt=""></p>
<p>有沒有看到熟悉的VGG呀，當年的第二名，也是CNN發展史上非常著名的一個模型呢</p>
<p>沒意外下一篇就是寫他了哈哈哈嗚嗚嗚嗚</p>
<h3 id="ILSVRC-2014-Detection-Challenge-Setup-and-Results"><a href="#ILSVRC-2014-Detection-Challenge-Setup-and-Results" class="headerlink" title="ILSVRC 2014 Detection Challenge Setup and Results"></a>ILSVRC 2014 Detection Challenge Setup and Results</h3><p>GoogLeNet也是當年Detection的冠軍呢，牛逼啊大佬</p>
<p>採用的方式和R-CNN類似，目前對於detection的著墨還不多，所以先不讀這部分，有興趣的可以再去看原文。</p>
<p><img src="https://meetonfriday.com/img/lazy-loading-animation.gif" data-original="https://res.cloudinary.com/meet-on-friday/image/upload/v1595630687/blog_posts/%E8%9E%A2%E5%B9%95%E5%BF%AB%E7%85%A7_2020-07-25_%E4%B8%8A%E5%8D%886.44.39_ng8hph.png" alt=""></p>
<h2 id="結論"><a href="#結論" class="headerlink" title="結論"></a>結論</h2><p>GoogLeNet提出了一個隨插隨用的區塊結構: Inception，直覺的想法就是讓模型自己去學最佳的結構(在該層中1x1, 3x3, 5x5 或是pooling誰比較重要就給予比較大的權重)。儘管設計看似很直覺，但在設計的背後考量並不是那麼簡單，要了解背後的設計動機需要花點時間看這篇論文。</p>
<p>然後這篇其實是GoogLeNet v1，之後還有v2 v3 v4的不同改進，有時間再來看看後續的發展。</p>
<p>而這篇文章中大量使用到了1x1 Conv，也使用到了GAP，這些技術都來自CV經典的論文: <strong>2014年ICLR的”Network in Network, NIN”</strong>，之後也會閱讀這篇文章。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a href="https://blog.csdn.net/lhanchao/article/details/55804968" target="_blank" rel="noopener">[深度学习] Going Deeper with Convolutions（GooLeNet）阅读笔记</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34326914" target="_blank" rel="noopener">论文阅读GoogLeNet Inception V1</a></li>
<li><a href="https://meetonfriday.com/posts/d5321308/">[論文速速讀]Gradient Based Learning Applied to Document Recognition</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32702031" target="_blank" rel="noopener">深入理解GoogLeNet结构（原创）</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32882744" target="_blank" rel="noopener">Going Deeper with Convolutions</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/68654281" target="_blank" rel="noopener">论文精读与分析：Inception V1:Going Deeper with Convolution</a></li>
</ul>

                <hr>
                <!-- Pager -->
                <ul class="pager">
    
    <li class="previous">
        <a href="/posts/4d6a906a/" data-toggle="tooltip" data-placement="top" title="[Pytorch]Pack the data to train variable length sequences">&larr; Newer Post</a>
    </li>
    
    
    <li class="next">
        <a href="/posts/3013fdb9/" data-toggle="tooltip" data-placement="top" title="[論文速速讀]Visualizing and Understanding Convolutional Networks">Older Post &rarr;</a>
    </li>
    
</ul>

                <!-- tip start -->
                

                
                <!-- tip end -->

                <!-- Sharing -->
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      
        <aside id="sidebar">
          <div id="toc" class="toc-article">
          <strong class="toc-title">Contents</strong>
          
            <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Abstract"><span class="toc-nav-number">1.</span> <span class="toc-nav-text">Abstract</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Introduction"><span class="toc-nav-number">2.</span> <span class="toc-nav-text">Introduction</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Related-Work"><span class="toc-nav-number">3.</span> <span class="toc-nav-text">Related Work</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Motivation-and-High-Level-Considerations"><span class="toc-nav-number">4.</span> <span class="toc-nav-text">Motivation and High Level Considerations</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#Architectural-Details"><span class="toc-nav-number">5.</span> <span class="toc-nav-text">Architectural Details</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#naive-version"><span class="toc-nav-number">5.1.</span> <span class="toc-nav-text">naive version</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Inception-module-with-dimension-reductions"><span class="toc-nav-number">5.2.</span> <span class="toc-nav-text">Inception module with dimension reductions</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#直覺上的設計考量"><span class="toc-nav-number">5.3.</span> <span class="toc-nav-text">直覺上的設計考量</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#1x1-Conv是如何降低計算量的"><span class="toc-nav-number">5.4.</span> <span class="toc-nav-text">1x1 Conv是如何降低計算量的?</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#GoogLeNet"><span class="toc-nav-number">6.</span> <span class="toc-nav-text">GoogLeNet</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#Training-Methodology"><span class="toc-nav-number">6.1.</span> <span class="toc-nav-text">Training Methodology</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#ILSVRC-2014-Classification-Challenge-Setup-and-Results"><span class="toc-nav-number">6.2.</span> <span class="toc-nav-text">ILSVRC 2014 Classification Challenge Setup and Results</span></a></li><li class="toc-nav-item toc-nav-level-3"><a class="toc-nav-link" href="#ILSVRC-2014-Detection-Challenge-Setup-and-Results"><span class="toc-nav-number">6.3.</span> <span class="toc-nav-text">ILSVRC 2014 Detection Challenge Setup and Results</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#結論"><span class="toc-nav-number">7.</span> <span class="toc-nav-text">結論</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#References"><span class="toc-nav-number">8.</span> <span class="toc-nav-text">References</span></a></li></ol>
          
          </div>
        </aside>
      
    

        </div>
    </div>
</article>

	
    <!-- disqus embedded js code start (one page only need to embed once) -->	
    <script type="text/javascript">	
        /* * * CONFIGURATION VARIABLES * * */	
        var disqus_shortname = "meetonfriday";	
        var disqus_identifier = "https://meetonfriday.com/posts/263e065d/";	
        var disqus_url = "https://meetonfriday.com/posts/263e065d/";	
        (function() {	
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;	
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';	
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);	
        })();	
    </script>	
    <!-- disqus embedded js code start end -->	
    

    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                
                    <li>
                        <a target="_blank"  href="https://github.com/john850512">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank"  href="https://www.linkedin.com/in/john85051232">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/meetonfridayyy">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank"  href="https://mail.google.com/mail/?view=cm&fs=1&to=john85051232@gmail.com">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-envelope-o fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; John 2025 
                    <br>
                    Powered by 
                    <a href="https://github.com/john850512/hexo-theme-jiji" target="_blank" rel="noopener">
                        <i>hexo-theme-jiji</i>
                    </a> | 
                    <iframe name="star" style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0"
                        width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=john850512&repo=hexo-theme-jiji&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://meetonfriday.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<!--<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>-->
<script async src="//cdn.jsdelivr.net/npm/busuanzi@2.3.0"></script>




	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        
        <!-- background effects end -->
    
    
    <!-- background animation-->>
    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var i=n.imageLazyLoadSetting.isSPA,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){i&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,e,a=0;a<r.length;a++)t=r[a],0<=(e=t.getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(n.innerHeight||document.documentElement.clientHeight)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},n.src=i}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body>

</html>
